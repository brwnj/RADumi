#!/usr/bin/env python
# encoding: utf-8
"""
Finding unique restriction site associated DNA (RAD) tag sequences per unique
molecular identifier (UMI).
"""
import sys
import editdist as ed
import subprocess as sp
from toolshed import nopen
from collections import Counter, defaultdict
from itertools import islice, groupby, izip

__version__ = "0.9"

IUPAC = {"A":"A","T":"T","C":"C","G":"G","R":"GA","Y":"TC",
         "M":"AC","K":"GT","S":"GC","W":"AT","H":"ACT",
         "B":"GTC","V":"GCA","D":"GAT","N":"GATC"}

def readfq(fq):
    class Fastq(object):
        def __init__(self, args):
            self.name = args[0][1:]
            self.seq = args[1]
            self.qual = args[3]
            assert len(self.seq) == len(self.qual)

        def __repr__(self):
            return "Fastq({name})".format(name=self.name)

        def __str__(self):
            return "@{name}\n{seq}\n+\n{qual}".format(name=self.name,
                    seq=self.seq, qual=self.qual)

    with nopen(fq) as fh:
        fqclean = (x.strip("\r\n") for x in fh if x.strip())
        while True:
            rd = [x for x in islice(fqclean, 4)]
            if not rd: raise StopIteration
            assert all(rd) and len(rd) == 4
            yield Fastq(rd)

def readfa(fa):
    class Fasta(object):
        def __init__(self, name, seq):
            self.name = name
            self.seq = seq

        def __repr__(self):
            return "Fasta({name})".format(name=self.name)

        def __str__(self):
            return ">{name}\n{seq}".format(
                        name=self.name,
                        seq="\n".join([self.seq[i:i + 70] for i in \
                                range(0, len(self.seq), 70)]))

    with nopen(fa) as fh:
        for header, group in groupby(fh, lambda line: line[0] == '>'):
            if header:
                line = group.next()
                name = line[1:].strip()
            else:
                seq = ''.join(line.strip() for line in group)
                yield Fasta(name, seq)

def valid_umi(iupac, umi):
    """parse UMI sequence to validate against IUPAC sequence."""
    for code, base in izip(iupac, umi):
        try:
            if not base in IUPAC[code]:
                return False
        except KeyError:
            return False
    return True

def run_dump(args):
    """incoming args: fastq, length"""
    leng = args.length
    for r in readfq(args.fastq):
        print ">{name}\n{umi}".format(name=r.name.split()[0], umi=r.seq[:leng])

def fasta_to_dict(fasta):
    d = {}
    for r in readfa(fasta):
        d[r.name.split()[0]] = r.seq
    return d

def run_add(args):
    """incoming args: fastq, fasta"""
    umi_d = fasta_to_dict(args.fasta)
    umi_qual = 'J' * len(umi_d[umi_d.keys()[0]])
    for r in readfq(args.fastq):
        try:
            umi = umi_d[r.name.split()[0]]
            assert len(umi) == len(umi_qual)
        except KeyError:
            # read not present in R1; flag with invalid UMI
            umi = 'X' * len(umi_qual)
        r.seq = "{umi}{seq}".format(umi=umi, seq=r.seq)
        r.qual = "{umi_qual}{qual}".format(umi_qual=umi_qual, qual=r.qual)
        print r

def run_sort(args):
    """fastq, length"""
    if args.fastq.endswith(".gz"):
        cmd = "gunzip -c %s | " % args.fastq
    else:
        cmd = "cat %s | " % args.fastq
    # sort by the UMI, then by read name for paired-end sync
    cmd += ("""awk '{printf($0);n++;if(n%4==0){printf("\\n")}else{printf("\\t")}}' | """
                """awk '{i=substr($2,1,length); print i"\\t"$0}' | """
                """sort -k1,1 -k2,2 | """
                """cut -f 2,3,4,5 | """
                """tr "\\t" "\\n\"""").replace("length", args.length)
    sp.call(cmd, shell=True)

def trimmed_seq(seq, leng, t5, t3):
    return seq[leng + t5:-t3] if t3 > 0 else seq[leng + t5:]

def distance(a, b):
    """find best edit distance between two strings without penalizing for
    length.
    """
    la, lb = len(a), len(b)
    if la < lb:
        return distance(b, a)
    if la == lb:
        return ed.distance(a, b)
    else:
        dists = []
        for i in xrange(0, la-lb+1):
            dists.append(ed.distance(a[i:i+lb], b))
        return min(dists)

def remove_matches(counter, mismatches):
    """filters based on Levenshtein distance. returns set."""
    # what to remove from the set
    ignore = set()
    # what to skip during iteration
    seen = set()
    # inherently ordered by abundance
    seqs = set(list(counter))
    for target in seqs:
        if target in seen: continue
        seen.add(target)
        for query in seqs:
            if query in seen: continue
            if distance(target, query) < mismatches:
                ignore.add(query)
                # no longer calculate distance for this query
                seen.add(query)
    return seqs - ignore

def run_scan(args):
    """fastq, umi, five, three"""
    iupacumi = args.umi.upper()
    umileng = len(iupacumi)
    five = args.five
    three = args.three
    mmatches = args.mismatches
    readid = 1
    for umi, group in groupby(readfq(args.fastq), key=lambda r: r.seq[:umileng]):
        if not valid_umi(iupacumi, umi): continue
        seqs = Counter()
        for r in group:
            seqs.update([trimmed_seq(r.seq, umileng, five, three)])
        if mmatches == 0:
            seqs = list(seqs)
        else:
            seqs = remove_matches(seqs, mmatches)
        # print fasta record of all unique sequences per UMI
        for seq in seqs:
            print ">read_{readid}:{umi}\n{seq}".format(**locals())
            readid += 1

def process_pairs(r1_out, r2_out, r1counter, r1dd, r2d, umi, mismatches, readid):
    """prints every unique read per umi"""
    ignore = set()
    seen = set()
    r1seqs = []
    r1seqs = set(list(r1counter))
    for target in r1seqs:
        if target in seen: continue
        seen.add(target)
        for query in r1seqs:
            if query in seen: continue
            if distance(target, query) < mismatches:
                for name in r1dd[query]:
                    # add similar read names to appropriate bin
                    r1dd[target].append(name)
                ignore.add(query)
                seen.add(query)
    chosen_seqs = r1seqs - ignore
    # find most abundant R2 and print reads
    for seq in chosen_seqs:
        r2seqs = Counter()
        for name in r1dd[seq]:
            # list of read names used in this bin
            r2seqs.update([r2d[name]])
        # print the fasta records
        r1_out.write(">read_{readid}:{umi} 1\n{seq}\n".format(**locals()))
        r2_out.write(">read_{readid}:{umi} 2\n{seq}\n".format(readid=readid, umi=umi, seq=r2seqs.most_common(1)[0][0]))
        readid += 1
    return readid

def run_scanp(args):
    """r1i, r2i, r1o, r2o, umi, mismatches, r1five, r1three, r2five, r2three"""
    iupacumi = args.umi
    umileng = len(iupacumi)
    r1five = args.r1five
    r1three = args.r1three
    r2five = args.r2five
    r2three = args.r2three
    mmatches = args.mismatches
    readid = 1
    with open(args.r1o, 'w') as r1o, open(args.r2o, 'w') as r2o:
        for umi, group in groupby(izip(readfq(args.r1i), readfq(args.r2i)), key=lambda (r1, r2): r1.seq[:umileng]):
            if not valid_umi(iupacumi, umi): continue
            # unique sequences
            r1seqs = Counter()
            # sequence to read name
            r1dd = defaultdict(list)
            r2d = {}
            for r1, r2 in group:
                r1.name = r1.name.split()[0]
                r2.name = r2.name.split()[0]
                # really no longer need the UMI on R2
                assert umi == r2.seq[:umileng]
                assert r1.name == r2.name
                # add the current sequence
                r1seq_trim = trimmed_seq(r1.seq, umileng, r1five, r1three)
                r2seq_trim = trimmed_seq(r2.seq, umileng, r2five, r2three)
                r1seqs.update([r1seq_trim])
                r1dd[r1seq_trim].append(r1.name)
                # dictionary of name to sequence
                r2d[r2.name] = r2seq_trim
            readid = process_pairs(r1o, r2o, r1seqs, r1dd, r2d, umi, mmatches, readid)

def main(args):
    args.func(args)

if __name__ == "__main__":
    import argparse
    p = argparse.ArgumentParser(description=__doc__, version=__version__)
    subp = p.add_subparsers(help='commands')

    # dump UMI sequence from R1 into fasta
    fdump = subp.add_parser('dump',
            description="Prints fasta of read name and 5' UMI sequence.",
            formatter_class=argparse.ArgumentDefaultsHelpFormatter,
            help="obtain fasta of read name and 5' UMI sequence")
    fdump.add_argument('fastq', metavar="FASTQ",
            help="fastq containing a UMI")
    fdump.add_argument('length', metavar="LENGTH", type=int,
            help="length of the UMI sequence")
    fdump.set_defaults(func=run_dump)

    # attach UMI of R1 onto R2 for identification
    fadd = subp.add_parser('add',
            description="Add UMI of dumped FASTA onto matched read name of \
                    FASTQ on the 5' end. Quality of the UMI will be 'J'.",
            formatter_class=argparse.ArgumentDefaultsHelpFormatter,
            help="add 5' UMI from dumped fasta onto reads of FASTQ")
    fadd.add_argument('fastq', metavar="FASTQ",
            help="reads onto which to add the UMI")
    fadd.add_argument('fasta', metavar="FASTA",
            help="dumped UMI sequences")
    fadd.set_defaults(func=run_add)

    # sorting the fastq by umi
    fsort = subp.add_parser('sort',
            description="Sorts fastq by UMI.",
            formatter_class=argparse.ArgumentDefaultsHelpFormatter,
            help="order the fastq by the UMI to facilitate processing")
    fsort.add_argument('fastq', metavar='FASTQ',
            help='unsorted reads with incorporated UMI')
    fsort.add_argument('length', metavar='LENGTH',
            help='length of the UMI sequence')
    fsort.set_defaults(func=run_sort)

    # find most abundance sequence per umi
    fscan = subp.add_parser('scan',
            description="Finds most abundant sequence per valid UMI.",
            formatter_class=argparse.ArgumentDefaultsHelpFormatter,
            help="find most abundant sequence per UMI")
    fscan.add_argument('fastq', metavar="FASTQ",
            help="reads with UMI to scan")
    fscan.add_argument('umi', metavar="UMI",
            help='IUPAC sequence of the UMI, e.g. NNNNNV')
    fscan.add_argument('-m', '--mismatches', type=int, default=3,
            help='allowable mismatches when finding unique sequences')
    fscan.add_argument('-5', dest='five', type=int, default=0,
            help="number of 5' bases to trim AFTER the UMI sequence")
    fscan.add_argument('-3', dest='three', type=int, default=0,
            help="number of 3' bases to trim")
    fscan.set_defaults(func=run_scan)

    # find most abundance sequence per umi among paired-end reads
    fscanp = subp.add_parser('scanp',
            description="Finds most abundant sequence per valid UMI among \
                    paired-end reads.",
            formatter_class=argparse.ArgumentDefaultsHelpFormatter,
            help="find most abundant sequence per UMI given paired-end reads")
    fscanp.add_argument('r1i', metavar="R1-IN",
            help="R1 FASTQ with UMI to scan.")
    fscanp.add_argument('r2i', metavar="R2-IN",
            help="R2 FASTQ with UMI to scan.")
    fscanp.add_argument('r1o', metavar="R1-OUT", help="R1 output FASTA.")
    fscanp.add_argument('r2o', metavar="R2-OUT", help="R2 output FASTA.")
    fscanp.add_argument('umi', metavar="UMI",
            help='IUPAC sequence of the UMI, e.g. NNNNNV')
    fscanp.add_argument('-m', '--mismatches', type=int, default=3,
            help='allowable mismatches when finding unique sequences')
    fscanp.add_argument('--r1-5', dest='r1five', type=int, default=0,
            help="number of 5' bases to trim AFTER the UMI sequence in R1")
    fscanp.add_argument('--r1-3', dest='r1three', type=int, default=0,
            help="number of 3' bases to trim in R1")
    fscanp.add_argument('--r2-5', dest='r2five', type=int, default=0,
            help="number of 5' bases to trim AFTER the UMI sequence in R2")
    fscanp.add_argument('--r2-3', dest='r2three', type=int, default=0,
            help="number of 3' bases to trim in R2")
    fscanp.set_defaults(func=run_scanp)

    args = p.parse_args()
    main(args)
